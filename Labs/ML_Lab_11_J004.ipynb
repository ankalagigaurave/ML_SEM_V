{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Lab 11 J004",
      "provenance": [],
      "authorship_tag": "ABX9TyPMa2TmRufar/HdcniMC1MG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankalagigaurave/ML_SEM_V/blob/master/Labs/ML_Lab_11_J004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "085S6rMQqiPu"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# For data visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# For building model and loading dataset\n",
        "import tensorflow as tf\n",
        "# Set basic configurations\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA54C_5Fq1PC"
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lyoTcJ2q7om"
      },
      "source": [
        "# Reading in the dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "# Looking at the first five rows of the DataFrame\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1WPYwSkq8WK"
      },
      "source": [
        "# slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "# Store the datetime values in a separate variable for future processing\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
        "# Looking at the first five rows of the DataFrame\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzkLAe57q88U"
      },
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)'] # Columns we want to plot\n",
        "plot_features = df[plot_cols] # Getting the columns\n",
        "plot_features.index = date_time # Setting the index as date time\n",
        "_ = plot_features.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygZ3EaXbq9KR"
      },
      "source": [
        "# Taking only first 480 points\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "# Plotting\n",
        "_ = plot_features.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V4GzvSiq-Mp"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml1pvdccrANr"
      },
      "source": [
        "# Getting indices of wv and max. wv with value -9999\n",
        "bad_wv = df['wv (m/s)'] == -9999.0\n",
        "bad_max_wv = df['max. wv (m/s)'] == -9999.0\n",
        "# Repalcing the incorrect values with 0.0\n",
        "df.loc[bad_wv,'wv (m/s)']  = 0.0\n",
        "df.loc[bad_max_wv, 'max. wv (m/s)']  = 0.0\n",
        "# Checking if the above inplace edits are reflected in the DataFrame\n",
        "df['wv (m/s)'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGNV8GJHrAlD"
      },
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "# Convert to radians\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "# Calculate the wind x and y components\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "# Calculate the max wind x and y components\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcofSsKHrA1Y"
      },
      "source": [
        "timestamp_s = date_time.map(datetime.datetime.timestamp)\n",
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvuxG50HrBDT"
      },
      "source": [
        "# Dictionary of column names and their indices, i.e., assigning indices to column names\n",
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "# Number of rows\n",
        "n = len(df)\n",
        "#  Splitting the dataset with a 70:20:10 split\n",
        "train_df = df[0:int(n*0.7)] # From 0% to 70%\n",
        "val_df = df[int(n*0.7):int(n*0.9)] # From 70% to 90%\n",
        "test_df = df[int(n*0.9):] # All above 90%\n",
        "# Number of features in our dataset\n",
        "num_features = df.shape[1]\n",
        "print(f'Total number of features: {num_features}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCjJBI9TrBQE"
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cyb399TrBcM"
      },
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LjIM8IQrBnw"
      },
      "source": [
        "# Taking only one column\n",
        "df_temp = pd.DataFrame(df['T (degC)'])\n",
        "df_temp.index = date_time \n",
        "# Displaying top 5 rows\n",
        "df_temp.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d--T9oBnrB0R"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install calmap\n",
        "import calmap\n",
        "# Defining figure size\n",
        "matplotlib.rcParams['figure.figsize'] = (12, 6)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqOS9tzrCAc"
      },
      "source": [
        "# Plot all temperature\n",
        "df_temp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tpx9OX0rCLj"
      },
      "source": [
        "# Group values of different years\n",
        "group_years = df_temp.groupby(df_temp.index.year)\n",
        "years = pd.DataFrame()\n",
        "for name, group in group_years:\n",
        "    values = group['T (degC)'].values\n",
        "    years[name] = pd.Series(values)\n",
        " \n",
        "# Plot data   \n",
        "years.plot(subplots=True, legend=True, figsize=(12,8))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8QNw30ZrCV4"
      },
      "source": [
        "# Getting data as pandas.Series\n",
        "temp = df_temp['T (degC)']\n",
        "# Plotting the Series\n",
        "temp.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIdFmj5irFVP"
      },
      "source": [
        "\n",
        "class WindowGenerator():\n",
        "    def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "        # Store the raw data. Refer to the previous chapter for the DataFrames.\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.test_df = test_df\n",
        "        # Work out the label column indices.\n",
        "        self.label_columns = label_columns\n",
        "        if label_columns is not None:\n",
        "            self.label_columns_indices = {name: i for i, name in\n",
        "                                        enumerate(label_columns)}\n",
        "        self.column_indices = {name: i for i, name in\n",
        "                               enumerate(train_df.columns)}\n",
        "        # Work out the window parameters.\n",
        "        self.input_width = input_width\n",
        "        self.label_width = label_width\n",
        "        self.shift = shift\n",
        "        self.total_window_size = input_width + shift\n",
        "        self.input_slice = slice(0, input_width)\n",
        "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "        self.label_start = self.total_window_size - self.label_width\n",
        "        self.labels_slice = slice(self.label_start, None)\n",
        "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "    def __repr__(self):\n",
        "        return '\\n'.join([\n",
        "            f'Total window size: {self.total_window_size}',\n",
        "            f'Input indices: {self.input_indices}',\n",
        "            f'Label indices: {self.label_indices}',\n",
        "            f'Label column name(s): {self.label_columns}'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTgVxaoLrFj4"
      },
      "source": [
        "\n",
        "# Predicting one hour into the future by using a data window of the past 6 hours\n",
        "w1 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "print(f'First Window: \\n{w1}')\n",
        "# Predicting 24 hours into the future by using a data window of the past 24 hours.\n",
        "w2 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "print(f'\\nSecond Window: \\n{w2}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veRJjCqXrFss"
      },
      "source": [
        "def split_window(self, features):\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.label_columns is not None:\n",
        "        labels = tf.stack(\n",
        "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "            axis=-1)\n",
        "    # Slicing doesn't preserve static shape information, so set the shapes\n",
        "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "    return inputs, labels\n",
        "WindowGenerator.split_window = split_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN74kX0crF0Q"
      },
      "source": [
        "# Stack three slices, the length of the total window:\n",
        "example_window = tf.stack([np.array(train_df[:w1.total_window_size]),\n",
        "                           np.array(train_df[100:100+w1.total_window_size]),\n",
        "                           np.array(train_df[200:200+w1.total_window_size])])\n",
        "example_inputs, example_labels = w1.split_window(example_window)\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'labels shape: {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oic3-xQ6rF8a"
      },
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "  ds = ds.map(self.split_window)\n",
        "  return ds\n",
        "WindowGenerator.make_dataset = make_dataset\n",
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGt3q3ijrGE1"
      },
      "source": [
        "w1.train.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-_v1aKOrGMy"
      },
      "source": [
        "for example_inputs, example_labels in w1.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLIryvfzrGU_"
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "single_step_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnHiniKjrGdY"
      },
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V88qSRa1rGl_"
      },
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]\n",
        "# Instantiatie and compile the model\n",
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALxyHBk1rGiW"
      },
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "wide_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa0W_RMcrGav"
      },
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21bgARezrGSQ"
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlriPzpPrGKI"
      },
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_WLIq0trGCB"
      },
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxKltF8_rF50"
      },
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOcLX6TArFxM"
      },
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}